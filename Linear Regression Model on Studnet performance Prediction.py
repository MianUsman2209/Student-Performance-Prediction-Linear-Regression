# -*- coding: utf-8 -*-
"""Session 01_Multiple_Linear Regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qVs4B9OBURCUrDjQpN_mAPzITJyUJhua

## Objective:
Develop a predictive model to estimate Student's Performance using linear regression.

### Description:
The Student Performance Dataset is a dataset designed to examine the factors influencing academic student performance. The dataset consists of 10,000 student records, with each record containing information about various predictors and a performance index.

#### Variables:

- **Hours Studied:** The total number of hours spent studying by each student.
- **Previous Scores:** The scores obtained by students in previous tests.
- **Extracurricular Activities:** Whether the student participates in extracurricular activities (Yes or No).
- **Sleep Hours:** The average number of hours of sleep the student had per day.
- **Sample Question Papers Practiced:** The number of sample question papers the student practiced.


#### Target Variable:

- **Performance Index:** A measure of the overall performance of each student. The performance index represents the student's academic performance and has been rounded to the nearest integer. The index ranges from 10 to 100, with higher values indicating better performance.


The dataset aims to provide insights into the relationship between the predictor variables and the performance index. Researchers and data analysts can use this dataset to explore the impact of studying hours, previous scores, extracurricular activities, sleep hours, and sample question papers on student performance.

P.S: Please note that this dataset is synthetic and created for illustrative purposes. The relationships between the variables and the performance index may not reflect real-world scenarios

### Loading Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")

"""### Loading Data"""

data = pd.read_csv("/content/Student_Performance (1).csv")

"""### Explore the Data"""

data.head()

"""### Data Structure"""

data.info()

"""### Statistical Summary"""

data.describe()

data.describe(include="object")

"""### Missing values"""

data.isnull().sum()

"""### Duplicates"""

data.duplicated().sum()

data.head()

"""###  Encoding"""

data =  pd.get_dummies(data,columns = ["Extracurricular Activities"], dtype=int)

data.head()

"""### Correlation matrix"""

correlation_matrix = data.corr()

# Plotting the correlation matrix
plt.figure(figsize=(8, 5))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix')
plt.show()

"""We will consider the column **"Extracurricular Activities_No"** as Extra and will drop it. Because this an inverse of column **"Extracurricular Activities_Yes"**."""

data.drop("Extracurricular Activities_No",axis=1,inplace=True)

data.head()

"""### Distribution"""

plt.figure(figsize=(15, 10))

# Iterate through each channel and plot on a separate subplot
for i, column in enumerate(data.columns):
    plt.subplot(3, 2, i+1)
    sns.histplot(data[column], kde=True)
    plt.title(f'Distribution of {column}')
    plt.xticks(rotation=45)

# Adjust layout and show the plot
plt.tight_layout()
plt.show()

"""### Normal Distribution Check"""

from scipy import stats

plt.figure(figsize=(15, 10))

# Iterate through each column and plot on a separate subplot
for i, column in enumerate(data.columns):
    plt.subplot(3, 2, i+1)
    sns.histplot(data[column], kde=True)
    plt.title(f'Distribution of {column}')
    plt.xticks(rotation=45)

    # Check for normal distribution
    k2, p = stats.normaltest(data[column])
    #print(k2, p )
    # null hyposthesis => The sample is from Normal dsitribution
    if (p > 0.05):
        plt.text(0.5, 0.5, "Normal", horizontalalignment='center', verticalalignment='center', transform=plt.gca().transAxes)
    else:
        plt.text(0.5, 0.5, "Not Normal", horizontalalignment='center', verticalalignment='center', transform=plt.gca().transAxes)

# Adjust layout and show the plot
plt.tight_layout()
plt.show()

import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import scipy.stats as stats

# Assuming you have a trained model and test data
# Calculate the residuals (errors)
y_pred = model.predict(X_test)  # Replace X_test with your test features
residuals = y_test - y_pred      # Replace y_test with your true test target values

# Plotting the histogram of residuals
plt.figure(figsize=(8, 6))
sns.histplot(residuals, kde=True)
plt.title('Histogram of Residuals')
plt.xlabel('Residuals')
plt.ylabel('Frequency')
plt.show()

# Q-Q plot to check normality
plt.figure(figsize=(8, 6))
stats.probplot(residuals, dist="norm", plot=plt)
plt.title('Q-Q Plot of Residuals')
plt.show()

"""### Skewed Distribution Check"""

plt.figure(figsize=(15, 10))

# Iterate through each column and plot on a separate subplot
for i, column in enumerate(data.columns):
    plt.subplot(3, 2, i+1)
    sns.histplot(data[column], kde=True)
    plt.title(f'Distribution of {column}')
    plt.xticks(rotation=45)

    # Check for skewness
    skewness = stats.skew(data[column])
    if skewness < -1 or skewness > 1:
        plt.text(0.5, 0.3, f"Skewed ({skewness:.2f})", horizontalalignment='center', verticalalignment='center', transform=plt.gca().transAxes)
    else:
        plt.text(0.5, 0.3, f"Not Skewed", horizontalalignment='center', verticalalignment='center', transform=plt.gca().transAxes)

# Adjust layout and show the plot
plt.tight_layout()
plt.show()

"""### Outlier Check"""

plt.figure(figsize=(18, 15))

# Iterate through each column and plot on a separate subplot
for i, column in enumerate(data.columns):
    plt.subplot(4, 2, i+1)
    sns.boxplot(data[column])
    plt.title(f'Box plot of {column}')

# Adjust layout and show the plot
plt.tight_layout()
plt.show()

"""## Multiple linear regression:

Multiple linear regression extends the principles of simple linear regression to scenarios where there are multiple independent variables influencing a single dependent variable. It's a powerful tool for understanding the relationships between several factors and how they collectively impact an outcome.

In multiple linear regression, the model seeks to find the best-fitting hyperplane through the multidimensional space of predictors to explain the variance in the dependent variable. Each independent variable contributes its own weight, represented by a coefficient \( b_n \), to the overall prediction. The model also includes a constant term \( b_0 \), analogous to the y-intercept in simple linear regression.

The equation for multiple linear regression can be expressed as:

\[ y = b_0 + b_1x_1 + b_2x_2 + ... + b_nx_n \]

Here, \( y \) represents the dependent variable, and \( x_1, x_2, ..., x_n \) represent the independent variables. Each \( b_n \) signifies the impact of the corresponding independent variable on the dependent variable, while \( b_0 \) captures the baseline value of \( y \) when all independent variables are zero.

By estimating the coefficients, the model can make predictions about the dependent variable based on specific values of the independent variables. The process of finding the optimal coefficients typically involves minimizing the sum of squared differences between the observed and predicted values, a method known as least squares regression.

Multiple linear regression is widely used across various fields, including economics, social sciences, engineering, and more. It enables researchers and analysts to uncover intricate relationships within complex datasets and make informed decisions based on predictive insights.
"""

data.head()

"""#### Define Features and Target"""

X = data.drop(columns = "Performance Index")
y = data["Performance Index"]

X.head(2)

y.head(2)

"""#### Split the dataset into training and testing sets.

"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# see shape of splited data

print("x_train shape: ", X_train.shape)
print("y_train shape: ", y_train.shape)
print("x_test shape: ", X_test.shape)
print("y_test shape: ", y_test.shape)

"""### Feature Scaling"""

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""### Implement a linear regression model.

"""

from sklearn.linear_model import LinearRegression

model = LinearRegression()

# fit model

model.fit(X_train,y_train)

"""#### Make predictions on the test set

"""

y_pred = model.predict(X_test)

len(y_pred)

y_test.count()

# Actual Values vs Predicted Values

pd.DataFrame({"Actual Performance" : y_test, "Predicted Performance" : y_pred})

"""### Evaluation Metrics

1. **R-squared (R2) Score:**
   - The R2 score, or coefficient of determination, measures the proportion of the variance in the dependent variable (y_test) that is predictable from the independent variable (y_pred).
   - It provides an indication of the goodness of fit of the model. The score ranges from 0 to 1, where 1 indicates a perfect fit.
   - The formula for R2 score is:
$$ R2 = 1 - \frac{\sum_{i=1}^{n} (y_{\text{test},i} - y_{\text{pred},i})^2}{\sum_{i=1}^{n} (y_{\text{test},i} - \bar{y}_{\text{test}})^2} $$

     - $ \bar{y}_{\text{test}}$  is the mean of the actual values (y_test).

   - In simpler terms, R2 represents the proportion of the variance in the actual values that is captured by the model. A higher R2 score suggests a better fit.
   - Ranges from 0 to 1, with higher values indicating a better fit.



2. **Mean Squared Error (MSE):**
   - The MSE, or mean squared error, is a measure of how much the predicted values differ from the actual values in a set of data.
   - It calculates the average of the squared differences between the predicted values (y_pred) and the actual values (y_test).
   - The formula for MSE is:
$$
MSE = \frac{1}{n} \sum_{i=1}^{n} (y_{\text{test},i} - y_{\text{pred},i})^2
$$

   - In simpler terms, it quantifies how "wrong" the model's predictions are on average.
   - Higher values indicate greater errors.
   

3. **Mean Absolute Error (MAE):**
   - The MAE, or mean absolute error, measures the average magnitude of errors in a set of predictions, without considering their direction (positive or negative).
   - It calculates the average of the absolute differences between the predicted values (y_pred) and the actual values (y_test).
   - The formula for MAE is:
$$
MAE = \frac{1}{n} \sum_{i=1}^{n} |y_{\text{test},i} - y_{\text{pred},i}|
$$
   - In simpler terms, it quantifies how "wrong" the model's predictions are on average, with higher values indicating greater errors. Unlike MSE, it does not square the errors, so large errors are not as heavily penalized.
   - Higher values indicate greater errors.
"""

# import libraries to model
from sklearn.metrics import mean_absolute_error,r2_score, mean_squared_error

r2 = r2_score(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)

print("R-squared Error: ",r2)
print("Mean Squared Error: ",mse)
print("Mean Absolute Error: ",mae)

# R-squared in percentage
print("R-squared Error: ",round(r2*100,3),'%')

"""#### Training vs Testing Accuracy"""

# Calculate the score of the model on the training data

model.score(X_train, y_train)

model.score(X_test, y_test)

import seaborn as sns

ax1 = sns.distplot(y_test, hist=False, color="r", label="Actual Value")
sns.distplot(y_pred, hist=False, color="b", label="Fitted Values" , ax=ax1)

"""### Model Interpretation:
1. Find coefficients of the linear regression model.

"""

model.coef_

coefficients = pd.DataFrame(model.coef_, X.columns, columns=['Coefficient'])

coefficients

coefficients.sort_values(by='Coefficient', ascending=False)

"""2. Find the intercept"""

# see y intercept

model.intercept_

"""# Cross-validation on the linear regression model"""

from sklearn.model_selection import cross_val_score, KFold

lm = LinearRegression()
scores = cross_val_score(lm, X,y, scoring='r2', cv=5)
scores

"""### Manual implementation of cross-validation"""

from sklearn.metrics import mean_squared_error
from sklearn.model_selection import KFold
import numpy as np

kf = KFold(n_splits=5, shuffle=True, random_state=42)
r2_scores = []

for train_index, test_index in kf.split(X):
    X_train_cv, X_test_cv = X.iloc[train_index], X.iloc[test_index]
    y_train_cv, y_test_cv = y.iloc[train_index], y.iloc[test_index]

    # Fit the model on the training set
    lm.fit(X_train_cv, y_train_cv)

    # Predict on the test set
    y_pred_cv = lm.predict(X_test_cv)

    # Calculate R² for each fold
    r = r2_score(y_test_cv, y_pred_cv)
    r2_scores.append(r)


    #Condition if you want to stop the folds on desired R2 scored
 #   if (r > 0.79):
  #      break


# Calculate the average R² across all folds
print([round(value,4) for value in r2_scores])
print("mean R2: ",np.mean(r2_scores))

"""### Basic Deployment"""

def predict_student_performance(model, scaler):
    # Input data from user
    hours_studied = float(input("Enter hours studied: "))
    previous_scores = float(input("Enter previous scores: "))
    extracurricular_activities = input("Participates in extracurricular activities (Yes/No): ").strip().lower()
    sleep_hours = float(input("Enter sleep hours: "))
    sample_question_papers_practiced = int(input("Enter number of sample question papers practiced: "))

    # Convert categorical input to numerical
    extracurricular_activities = 1 if extracurricular_activities.lower() == 'yes' else 0

    # Create a dataframe for the input data
    input_data = pd.DataFrame([[hours_studied, previous_scores, sleep_hours, sample_question_papers_practiced, extracurricular_activities]],
                              columns=['Hours Studied', 'Previous Scores', 'Sleep Hours', 'Sample Question Papers Practiced', 'Extracurricular Activities_Yes'])
    # Scale the input data
    input_data_scaled = scaler.transform(input_data)

    # Predict performance
    prediction = model.predict(input_data_scaled)

    return prediction[0]



predicted_performance = predict_student_performance(model, scaler)
print(f"Predicted Performance Index: {predicted_performance:.2f}")

